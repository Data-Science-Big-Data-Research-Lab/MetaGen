{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T09:19:33.025321Z",
     "start_time": "2025-02-04T09:18:21.994953Z"
    }
   },
   "outputs": [],
   "source": [
    "from functions import BECHMARK_FUNCTIONS, FUNCTION_RANGES\n",
    "import numpy as np\n",
    "import time\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler, TPESampler\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from ray import tune\n",
    "from ray.tune.search import BasicVariantGenerator\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from hyperopt import fmin, tpe, rand, hp, Trials\n",
    "from itertools import product\n",
    "from metagen.framework import Domain\n",
    "from metagen.logging.metagen_logger import metagen_logger\n",
    "from metagen.metaheuristics import RandomSearch, TPE\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import fetch_california_housing, load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T09:20:43.229299Z",
     "start_time": "2025-02-04T09:20:43.205909Z"
    }
   },
   "outputs": [],
   "source": [
    "ITERATIONS_PER_RUN = 100\n",
    "from metagen.metaheuristics.gamma_schedules import GammaConfig\n",
    "# Data\n",
    "data = fetch_california_housing()\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "\n",
    "data.data = scaler_x.fit_transform(data.data)\n",
    "data.target = scaler_y.fit_transform(data.target.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Criterion for DecisionTreeRegressor\n",
    "criterion = [\"squared_error\", \"friedman_mse\", \"poisson\"]\n",
    "\n",
    "def get_model(model_name, seed, **kwargs):\n",
    "    if model_name == \"elasticnet\":\n",
    "        return ElasticNet(random_state=seed, **kwargs)\n",
    "    elif model_name == \"decision_tree\":\n",
    "        return DecisionTreeRegressor(random_state=seed, **kwargs)\n",
    "    elif model_name == \"sgd\":\n",
    "        return SGDRegressor(random_state=seed, **kwargs)\n",
    "    elif model_name == \"svr\":\n",
    "        return SVR(**kwargs)\n",
    "    elif model_name == \"bayesian_ridge\":\n",
    "        return BayesianRidge(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_name\")\n",
    "\n",
    "def optuna_objective(trial, seed, model_name):\n",
    "    if model_name == \"elasticnet\":\n",
    "        clf = get_model(model_name, seed, \n",
    "                        alpha=trial.suggest_float('alpha', 1e-6, np.log(1e5)), \n",
    "                        l1_ratio=trial.suggest_float('l1_ratio', 1e-6, 1))\n",
    "    elif model_name == \"decision_tree\":\n",
    "        clf = get_model(model_name, seed, \n",
    "                        min_samples_split=trial.suggest_int(f'min_samples', 2, 128), \n",
    "                        criterion=criterion[trial.suggest_int(f'criterion', 0, 2)])\n",
    "    elif model_name == \"sgd\":\n",
    "        clf = get_model(model_name, seed, \n",
    "                        alpha=trial.suggest_float('alpha', 1e-6, np.log(1e5)),\n",
    "                        l1_ratio=trial.suggest_float('l1_ratio', 1e-6, 1))\n",
    "    elif model_name == \"svr\":\n",
    "        clf = get_model(model_name, seed, \n",
    "                        C=trial.suggest_float('C', 1e-3, 1e3), \n",
    "                        epsilon=trial.suggest_float('epsilon', 1e-3, 1))\n",
    "    elif model_name == \"bayesian_ridge\":\n",
    "        clf = get_model(model_name, seed,\n",
    "                        alpha_1=trial.suggest_float('alpha_1', 1e-6, 1e-1),\n",
    "                        alpha_2=trial.suggest_float('alpha_2', 1e-6, 1e-1),\n",
    "                        lambda_1=trial.suggest_float('lambda_1', 1e-6, 1e-1),\n",
    "                        lambda_2=trial.suggest_float('lambda_2', 1e-6, 1e-1))\n",
    "\n",
    "    return -cross_val_score(clf, data.data, data.target, cv=3, scoring=\"neg_mean_absolute_error\").mean()\n",
    "\n",
    "def run_optuna(search_algorithm=\"random\", seed=0, model_name=\"elasticnet\"):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    start_time = time.time()\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', \n",
    "                                sampler=TPESampler(seed=seed) if search_algorithm == \"tpe\" else RandomSampler(seed=seed))\n",
    "    study.optimize(lambda trial: optuna_objective(trial, seed, model_name), \n",
    "                   n_trials=ITERATIONS_PER_RUN, show_progress_bar=False)\n",
    "    best_values = [t.value for t in study.trials if t.value is not None]\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    return {\"library\": \"optuna\", \"search_algorithm\": search_algorithm,\n",
    "            \"best_value\": study.best_value, **study.best_params,\n",
    "            \"time\": end_time - start_time, \"seed\": seed, \"best_values\": deepcopy(best_values)}\n",
    "\n",
    "def hyperopt_objective(params, seed, model_name):\n",
    "    clf = get_model(model_name, seed, **params)\n",
    "    return -cross_val_score(clf, data.data, data.target, cv=3, scoring=\"neg_mean_absolute_error\").mean()\n",
    "\n",
    "def run_hyperopt(search_algorithm=\"random\", seed=0, model_name=\"elasticnet\"):\n",
    "    if model_name == \"elasticnet\" or model_name == \"sgd\":\n",
    "        search_space = {\"alpha\": hp.uniform('alpha', 1e-6, np.log(1e5)),\n",
    "                        \"l1_ratio\": hp.uniform('l1_ratio', 1e-6, 1)}\n",
    "    elif model_name == \"decision_tree\":\n",
    "        search_space = {\"min_samples_split\": hp.choice('min_samples_split', list(range(2, 129))),\n",
    "                        \"criterion\": hp.choice('criterion', criterion)}\n",
    "    elif model_name == \"svr\":\n",
    "        search_space = {\"C\": hp.uniform('C', 1e-3, 1e3),\n",
    "                        \"epsilon\": hp.uniform('epsilon', 1e-3, 1)}\n",
    "    elif model_name == \"bayesian_ridge\":\n",
    "        search_space = {\n",
    "            \"alpha_1\": hp.uniform('alpha_1', 1e-6, 1e-1),\n",
    "            \"alpha_2\": hp.uniform('alpha_2', 1e-6, 1e-1),\n",
    "            \"lambda_1\": hp.uniform('lambda_1', 1e-6, 1e-1),\n",
    "            \"lambda_2\": hp.uniform('lambda_2', 1e-6, 1e-1)\n",
    "        }\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    trials = Trials()\n",
    "    start_time = time.time()\n",
    "    best = fmin(\n",
    "        fn=lambda params: hyperopt_objective(params, seed, model_name),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest if search_algorithm == \"tpe\" else rand.suggest,\n",
    "        max_evals=ITERATIONS_PER_RUN,\n",
    "        trials=trials,\n",
    "        show_progressbar=False,\n",
    "        rstate=np.random.default_rng(seed)\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    best_loss = min(trials.losses())\n",
    "\n",
    "    return {\"library\": \"hyperopt\", \"search_algorithm\": search_algorithm, \n",
    "            \"best_value\": best_loss, **best,\n",
    "            \"time\": end_time - start_time, \"seed\": seed, \"best_values\": deepcopy(trials.losses())}\n",
    "\n",
    "def metagen_objective(solution, seed, model_name):\n",
    "\n",
    "    solution_copy = deepcopy(solution)\n",
    "    #solution_copy.value[\"min_samples_split\"] = solution_copy.value[\"min_samples_split\"].value\n",
    "    #solution_copy.value[\"criterion\"] = criterion[solution_copy.value[\"criterion\"].value]\n",
    "\n",
    "    for key in solution_copy.value.keys():\n",
    "        if key == \"criterion\":\n",
    "            solution_copy.value[key] = criterion[solution_copy.value[key].value]\n",
    "        else:\n",
    "            solution_copy.value[key] = solution_copy.value[key].value\n",
    "\n",
    "    clf = get_model(model_name, seed, **solution_copy.value)\n",
    "    return -cross_val_score(clf, data.data, data.target, cv=3, scoring=\"neg_mean_absolute_error\").mean()\n",
    "\n",
    "def run_metagen(search_algorithm=\"random\", seed=0, model_name=\"elasticnet\"):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    metagen_logger.setLevel(\"ERROR\")\n",
    "\n",
    "    domain = Domain()\n",
    "\n",
    "    if model_name == \"elasticnet\" or model_name == \"sgd\":\n",
    "        domain.define_real(\"alpha\", 1e-6, np.log(1e5))\n",
    "        domain.define_real(\"l1_ratio\", 1e-6, 1)\n",
    "    elif model_name == \"decision_tree\":\n",
    "        domain.define_integer(\"min_samples_split\", 2, 128)\n",
    "        domain.define_integer(\"criterion\", 0, 2)\n",
    "    elif model_name == \"svr\":\n",
    "        domain.define_real(\"C\", 1e-3, 1e3)\n",
    "        domain.define_real(\"epsilon\", 1e-3, 1)\n",
    "    elif model_name == \"bayesian_ridge\":\n",
    "        domain.define_real(\"alpha_1\", 1e-6, 1e-1)\n",
    "        domain.define_real(\"alpha_2\", 1e-6, 1e-1)\n",
    "        domain.define_real(\"lambda_1\", 1e-6, 1e-1)\n",
    "        domain.define_real(\"lambda_2\", 1e-6, 1e-1)\n",
    "\n",
    "    if search_algorithm == \"tpe\":\n",
    "        search = TPE(domain, lambda solution: metagen_objective(solution, seed, model_name), \n",
    "                     candidate_pool_size=ITERATIONS_PER_RUN // (ITERATIONS_PER_RUN // 10),\n",
    "                     max_iterations=ITERATIONS_PER_RUN // 10)\n",
    "    else:\n",
    "        search = RandomSearch(domain, lambda solution: metagen_objective(solution, seed, model_name), \n",
    "                              population_size=ITERATIONS_PER_RUN // (ITERATIONS_PER_RUN // 10), \n",
    "                              max_iterations=ITERATIONS_PER_RUN // 10)\n",
    "\n",
    "    start_time = time.time()\n",
    "    best_solution = search.run()\n",
    "    end_time = time.time()\n",
    "\n",
    "    return {\"library\": \"metagen\", \"search_algorithm\": search_algorithm, \n",
    "            \"best_value\": best_solution.get_fitness(), **best_solution.value,\n",
    "            \"time\": end_time - start_time, \"seed\": seed, \n",
    "            \"best_values\": search.best_solution_fitnesses}\n",
    "\n",
    "def run_baseline(search_algorithm=None, seed=0, model_name=\"elasticnet\"):\n",
    "    start_time = time.time()\n",
    "    clf = get_model(model_name, seed)\n",
    "    best_value = -cross_val_score(clf, data.data, data.target, scoring=\"neg_mean_absolute_error\", cv=3).mean()\n",
    "    end_time = time.time()\n",
    "\n",
    "    return {\"library\": \"baseline\", \"search_algorithm\": search_algorithm, \n",
    "            \"best_value\": best_value, \"time\": end_time - start_time, \n",
    "            \"seed\": seed, \"best_values\": []}\n",
    "\n",
    "def run_multiple_seeds(run_func, search_algorithm=\"random\", num_seeds=10, model_name=\"elasticnet\"):\n",
    "    results = []\n",
    "    for seed in range(num_seeds):\n",
    "        result = run_func(search_algorithm, seed, model_name)\n",
    "        results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-04T09:20:58.768519Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "NUM_SEEDS = 10\n",
    "\n",
    "all_results = []\n",
    "\n",
    "model_name = \"decision_tree\"\n",
    "\n",
    "for library, search_algorithm in tqdm(list(product([run_baseline, run_optuna, run_hyperopt, run_metagen], [\"tpe\"])), desc=\"Overall Progress\"): #run_baseline, run_optuna, run_hyperopt,\n",
    "    results = run_multiple_seeds(library, search_algorithm, NUM_SEEDS, model_name)\n",
    "    all_results.extend(results)\n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    df.to_csv(f\"{model_name}_results_v3.csv\", index=False)\n",
    "\n",
    "# for library, search_algorithm in tqdm(list(product([run_baseline, run_optuna, run_hyperopt, run_metagen], [\"random\", \"tpe\"])), desc=\"Overall Progress\"): #run_baseline, run_optuna, run_hyperopt,\n",
    "#     results = run_multiple_seeds(library, search_algorithm, NUM_SEEDS, model_name)\n",
    "#     all_results.extend(results)\n",
    "#\n",
    "#     df = pd.DataFrame(all_results)\n",
    "#\n",
    "#     df.to_csv(f\"{model_name}_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T17:30:10.299422Z",
     "start_time": "2025-02-03T17:30:10.291183Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt = pd.read_csv(\"decision_tree_results_v3.csv\")\n",
    "df_dt[\"model\"] = \"dt\"\n",
    "\n",
    "#df_sgd = pd.read_csv(\"sgd_results.csv\")\n",
    "#df_sgd[\"model\"] = \"sgd\"\n",
    "\n",
    "#df_sgd_metagen = pd.read_csv(\"sgd_results_metagen.csv\")\n",
    "#df_sgd[\"model\"] = \"sgd\"\n",
    "\n",
    "# df_bayesian = pd.read_csv(\"bayesian_ridge_results.csv\")\n",
    "# df_bayesian[\"model\"] = \"bayesian\"\n",
    "#\n",
    "df_elasticnet = pd.read_csv(\"elasticnet_results_v3.csv\")\n",
    "df_elasticnet[\"model\"] = \"elasticnet\"\n",
    "\n",
    "df = pd.concat([df_dt, df_elasticnet]).reset_index(drop=True) #df_sgd\n",
    "\n",
    "df[\"best_values\"] = df.best_values.apply(eval)\n",
    "\n",
    "df.loc[df.best_values.apply(len) == 0, \"library\"] = \"baseline\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_arrays(arrays):\n",
    "\n",
    "    if len(arrays.values[0]) == 0:\n",
    "        return []\n",
    "    \n",
    "    averaged_values = np.mean(np.stack(arrays.values), axis=0)\n",
    "\n",
    "    best_trial_evolution = np.minimum.accumulate(averaged_values)\n",
    "\n",
    "    return best_trial_evolution\n",
    "\n",
    "def calculate_convergence_rate(best_values):\n",
    "    \n",
    "    return sum([(best_values[i+1] - best_values[i])*100 / best_values[i] for i in range(len(best_values) - 1)]) / (len(best_values) -1)\n",
    "\n",
    "averaged_arrays = df.groupby([ \"library\", \"search_algorithm\", \"model\"])[\"best_values\"].apply(average_arrays)\n",
    "\n",
    "convergence_rate = averaged_arrays.apply(calculate_convergence_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_metrics = df.groupby([ \"library\", \"search_algorithm\", \"model\"]).mean(numeric_only=True)\n",
    "grouped_metrics[\"best_values\"] = averaged_arrays\n",
    "grouped_metrics[\"convergence_rate\"] = convergence_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_metrics[[\"best_value\", \"time\", \"convergence_rate\"]].reset_index().pivot(index=[\"library\", \"model\"], columns=\"search_algorithm\", values=[\"best_value\", \"time\", \"convergence_rate\"]).round(3).to_latex(\"results_ml_v2.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_metrics[grouped_metrics.index.get_level_values(1)==\"tpe\"]#.to_latex(\"results_tpe.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reescale_evolution(arr):\n",
    "    n = len(arr) // 10\n",
    "    \n",
    "    min_values = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        chunk = arr[i*10:(i+1)*10]\n",
    "        min_values.append(np.min(chunk))\n",
    "    \n",
    "    if len(arr) % 10 != 0:\n",
    "        min_values.append(np.min(arr[n*10:]))\n",
    "    \n",
    "    return np.array(min_values)\n",
    "\n",
    "for search_algorithm in [\"random\", \"tpe\"]:\n",
    "\n",
    "    filtered_metrics = grouped_metrics[(grouped_metrics.index.get_level_values(1)==search_algorithm)]\n",
    "\n",
    "    plt.figure(figsize=(20, 10), tight_layout=True)\n",
    "    plt.title(f' {search_algorithm.capitalize()}', fontdict={'size': 20})\n",
    "    for (library, search_algorithm), row in filtered_metrics.iterrows():\n",
    "\n",
    "        best_values = row['best_values'] if library == \"metagen\" else reescale_evolution(row['best_values'])\n",
    "\n",
    "\n",
    "        plt.plot(best_values, label=f'{library.capitalize()} ({round(row[\"convergence_rate\"]*100, 2)})', linewidth=2)\n",
    "        plt.xlabel('Iteration', fontdict={'size': 20})\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.ylabel('Best Value', fontdict={'size': 20})\n",
    "        plt.yticks(fontsize=18)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.roll(row['best_values']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average(row['best_values'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row[['best_values']].rolling(10).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "# Iterate over each group in the grouped_metrics dataframe\n",
    "for (function_name, library, search_algorithm), row in grouped_metrics[grouped_metrics.index.get_level_values(2)==\"tpe\"].iterrows():\n",
    "    plt.plot(row['best_values'], label=f'{library} - {search_algorithm}')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Best Value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
